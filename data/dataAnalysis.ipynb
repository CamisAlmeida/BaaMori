{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73c0fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo 'fall_dataset_final.csv' gerado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Arquivos CSV de queda e atividade normal\n",
    "file_paths = {\n",
    "    \"QuedaFrente\": \"QuedaFrente.csv\",\n",
    "    \"QuedaFrenteSentado\": \"QuedaFrenteSentado.csv\",\n",
    "    \"QuedaLadoSentado\": \"QuedaLadoSentado.csv\",\n",
    "    \"QuedaLateral\": \"QuedaLateral.csv\",\n",
    "    \"QuedaTraz\": \"QuedaTraz.csv\",\n",
    "    \"QuedaTrazSentado\": \"QuedaTrazSentado.csv\",\n",
    "    \"QuedaTrazSentar\": \"QuedaTrazSentar.csv\",\n",
    "    \"dbNoFall\": \"dbNoFall.csv\"\n",
    "}\n",
    "\n",
    "# Lê todos os arquivos\n",
    "dataframes = {name: pd.read_csv(path) for name, path in file_paths.items()}\n",
    "\n",
    "\n",
    "def process_falls(df, label=1, min_size=5):\n",
    "    grouped = df.groupby('Teste')\n",
    "    processed_rows = []\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) < min_size:\n",
    "            continue  # Ignorar quedas muito curtas\n",
    "        group = group.drop(columns=['Time(ms)', 'Teste'], errors='ignore')\n",
    "        flat_values = group.iloc[:min_size].to_numpy().flatten()  # Usar só os primeiros 5\n",
    "        processed_rows.append(flat_values)\n",
    "\n",
    "    if not processed_rows:\n",
    "        return pd.DataFrame()  # Retornar vazio se nada válido\n",
    "\n",
    "    base_columns = group.columns\n",
    "    num_features = len(base_columns)\n",
    "    max_len = max(len(row) for row in processed_rows)\n",
    "\n",
    "    col_names = []\n",
    "    for i in range(max_len // num_features):\n",
    "        for col in base_columns:\n",
    "            col_names.append(f\"{col}{i+1}\")\n",
    "\n",
    "    df_processed = pd.DataFrame(processed_rows, columns=col_names)\n",
    "    df_processed.insert(0, \"isFall\", label)\n",
    "    return df_processed\n",
    "\n",
    "\n",
    "def process_no_fall(df, group_size=5, label=0):\n",
    "    df = df.drop(columns=['Time(ms)', 'Teste'], errors='ignore')\n",
    "    processed_rows = []\n",
    "\n",
    "    for i in range(0, len(df), group_size):\n",
    "        group = df.iloc[i:i+group_size]\n",
    "        if len(group) < group_size:\n",
    "            continue\n",
    "        flat_values = group.to_numpy().flatten()\n",
    "        processed_rows.append(flat_values)\n",
    "\n",
    "    if not processed_rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    base_columns = df.columns\n",
    "    num_features = len(base_columns)\n",
    "    max_len = max(len(row) for row in processed_rows)\n",
    "\n",
    "    col_names = []\n",
    "    for i in range(max_len // num_features):\n",
    "        for col in base_columns:\n",
    "            col_names.append(f\"{col}{i+1}\")\n",
    "\n",
    "    df_processed = pd.DataFrame(processed_rows, columns=col_names)\n",
    "    df_processed.insert(0, \"isFall\", label)\n",
    "    return df_processed\n",
    "\n",
    "\n",
    "# Processar quedas\n",
    "falls_dfs = []\n",
    "for name, df in dataframes.items():\n",
    "    if name != \"dbNoFall\":\n",
    "        processed_df = process_falls(df, label=1)\n",
    "        if not processed_df.empty:\n",
    "            falls_dfs.append(processed_df)\n",
    "\n",
    "falls_final_df = pd.concat(falls_dfs, ignore_index=True)\n",
    "\n",
    "# Processar atividade normal\n",
    "no_fall_df = process_no_fall(dataframes[\"dbNoFall\"], group_size=5, label=0)\n",
    "\n",
    "# Combinar tudo\n",
    "final_dataset = pd.concat([falls_final_df, no_fall_df], ignore_index=True)\n",
    "\n",
    "# Limpar valores inválidos\n",
    "final_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "final_dataset.dropna(inplace=True)\n",
    "\n",
    "# Salvar no CSV\n",
    "final_dataset.to_csv(\"fall_dataset_final.csv\", index=False)\n",
    "print(\"✅ Arquivo 'fall_dataset_final.csv' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cff48fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da classe queda (aumentada): 193\n",
      "Tamanho da classe não queda: 193\n",
      "Tamanho total do dataset balanceado: 386\n",
      "✅ Arquivo 'fall_dataset_balanced.csv' gerado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separar as classes\n",
    "df_fall = final_dataset[final_dataset['isFall'] == 1]\n",
    "df_no_fall = final_dataset[final_dataset['isFall'] == 0]\n",
    "\n",
    "# Quantidade da maior classe\n",
    "max_size = len(df_no_fall)\n",
    "\n",
    "# Aumentar a classe minoritária (queda) com reposição até igualar o tamanho da maior\n",
    "df_fall_upsampled = resample(df_fall,\n",
    "                             replace=True,        # amostragem com reposição\n",
    "                             n_samples=max_size,  # igualar tamanho da classe maior\n",
    "                             random_state=42)     # para reproducibilidade\n",
    "\n",
    "# Juntar as duas classes balanceadas\n",
    "df_balanced = pd.concat([df_no_fall, df_fall_upsampled])\n",
    "\n",
    "# Embaralhar as linhas para misturar as classes\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Tamanho da classe queda (aumentada): {len(df_fall_upsampled)}\")\n",
    "print(f\"Tamanho da classe não queda: {len(df_no_fall)}\")\n",
    "print(f\"Tamanho total do dataset balanceado: {len(df_balanced)}\")\n",
    "\n",
    "# Salvar no CSV\n",
    "df_balanced.to_csv(\"fall_dataset_balanced.csv\", index=False)\n",
    "print(\"✅ Arquivo 'fall_dataset_balanced.csv' gerado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafddb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[54  4]\n",
      " [ 2 56]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        58\n",
      "           1       0.93      0.97      0.95        58\n",
      "\n",
      "    accuracy                           0.95       116\n",
      "   macro avg       0.95      0.95      0.95       116\n",
      "weighted avg       0.95      0.95      0.95       116\n",
      "\n",
      "\n",
      "Árvore de Decisão (em texto):\n",
      "\n",
      "|--- GyrX(d/s)2 <= 3908.78\n",
      "|   |--- GyrX(d/s)3 <= 3900.97\n",
      "|   |   |--- AccZ(g)1 <= 15.73\n",
      "|   |   |   |--- AccZ(g)2 <= 0.04\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- AccZ(g)2 >  0.04\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- AccZ(g)1 >  15.73\n",
      "|   |   |   |--- ΔAccZ1 <= -26.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- ΔAccZ1 >  -26.00\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- GyrX(d/s)3 >  3900.97\n",
      "|   |   |--- AccZ(g)2 <= 0.44\n",
      "|   |   |   |--- AccX(g)1 <= 0.81\n",
      "|   |   |   |   |--- GyrZ(d/s)3 <= 3.78\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- GyrZ(d/s)3 >  3.78\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- AccX(g)1 >  0.81\n",
      "|   |   |   |   |--- AccY(g)5 <= 31.38\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- AccY(g)5 >  31.38\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- AccZ(g)2 >  0.44\n",
      "|   |   |   |--- ΔGyrZ3 <= -32964.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- ΔGyrZ3 >  -32964.00\n",
      "|   |   |   |   |--- AccX(g)5 <= 31.89\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- AccX(g)5 >  31.89\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|--- GyrX(d/s)2 >  3908.78\n",
      "|   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv(\"fall_dataset_balanced.csv\")  \n",
    "\n",
    "# Separar variáveis e rótulo\n",
    "X = df.drop(columns=[\"isFall\"])\n",
    "y = df[\"isFall\"]\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Criar e treinar o modelo\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=42)  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Exibir a árvore de decisão em texto\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "tree_rules = export_text(clf, feature_names=list(X.columns))\n",
    "print(\"\\nÁrvore de Decisão (em texto):\\n\")\n",
    "print(tree_rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
